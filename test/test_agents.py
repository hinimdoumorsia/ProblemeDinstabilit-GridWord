# test_agents.py
import numpy as np
from gridworld_env import GridWorld
from agent_immediate import DQNAgentImmediate
from agent_periodic import DQNAgentPeriodic

def test_single_agent(agent, env, agent_name, episodes=3):
    """Teste un agent spÃ©cifique"""
    print(f"\n{'='*60}")
    print(f"TEST DE L'AGENT: {agent_name}")
    print(f"{'='*60}")
    
    for episode in range(episodes):
        state = env.reset()
        total_reward = 0
        steps = 0
        done = False
        trajectory = [env.agent_pos.copy()]
        
        print(f"\nğŸ¯ Ã‰pisode {episode + 1}")
        print(f"ğŸ“ DÃ©part: Agent {env.agent_pos}, But {env.goal_pos}")
        env.render()
        
        while not done and steps < 20:
            # Sauvegarder l'epsilon original et le mettre Ã  0 pour le test
            original_epsilon = agent.epsilon
            agent.epsilon = 0.0
            
            action = agent.act(state)
            
            # Restaurer l'epsilon
            agent.epsilon = original_epsilon
            
            state, reward, done = env.step(action)
            total_reward += reward
            steps += 1
            trajectory.append(env.agent_pos.copy())
            
            action_names = ["â†‘ Haut", "â†’ Droite", "â†“ Bas", "â† Gauche"]
            print(f"  Step {steps}: {action_names[action]} â†’ Agent {env.agent_pos} (Reward: {reward:.1f})")
            
            if done:
                print(f"  ğŸ‰ BUT ATTEINT!")
                env.render()
        
        print(f"ğŸ“Š Score final: {total_reward:.2f}, Steps: {steps}")
        print(f"ğŸ›£ï¸  Trajectoire: {trajectory}")
        
        # DÃ©placer le but pour le prochain test
        if episode < episodes - 1:  # Ne pas dÃ©placer aprÃ¨s le dernier Ã©pisode
            env.move_goal()

def test_performance(agent, agent_name, num_episodes=50):
    """Test quantitatif de la performance"""
    env = GridWorld(size=5)
    scores = []
    steps_to_goal = []
    success_count = 0
    
    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0
        steps = 0
        done = False
        
        # Mettre epsilon Ã  0 pour l'Ã©valuation
        original_epsilon = agent.epsilon
        agent.epsilon = 0.0
        
        while not done and steps < 50:
            action = agent.act(state)
            state, reward, done = env.step(action)
            total_reward += reward
            steps += 1
        
        # Restaurer l'epsilon
        agent.epsilon = original_epsilon
        
        scores.append(total_reward)
        if done:
            steps_to_goal.append(steps)
            success_count += 1
        
        env.move_goal()
    
    success_rate = (success_count / num_episodes) * 100
    avg_steps = np.mean(steps_to_goal) if steps_to_goal else float('inf')
    avg_score = np.mean(scores)
    
    print(f"\nğŸ“ˆ Performance {agent_name}:")
    print(f"   Score moyen: {avg_score:.2f} Â± {np.std(scores):.2f}")
    print(f"   Taux de succÃ¨s: {success_rate:.1f}%")
    print(f"   Steps moyens pour atteindre le but: {avg_steps:.1f}" if steps_to_goal else "   Aucun but atteint")
    print(f"   Meilleur score: {np.max(scores):.2f}")
    print(f"   Pire score: {np.min(scores):.2f}")
    
    return avg_score, success_rate

def compare_agents():
    """Compare les deux agents entraÃ®nÃ©s"""
    
    # Configuration
    env = GridWorld(size=5)
    state_size = 4
    action_size = 4
    
    # Chargement des agents
    print("Chargement des agents...")
    
    # Agent immÃ©diat
    immediate_agent = DQNAgentImmediate(state_size, action_size)
    try:
        immediate_agent.load("immediate_agent.pth")
        print("âœ… Agent immÃ©diat chargÃ© avec succÃ¨s")
    except FileNotFoundError:
        print("âŒ Fichier immediate_agent.pth non trouvÃ©")
        return
    except Exception as e:
        print(f"âŒ Erreur lors du chargement de l'agent immÃ©diat: {e}")
        return
    
    # Agent pÃ©riodique
    periodic_agent = DQNAgentPeriodic(state_size, action_size)
    try:
        periodic_agent.load("periodic_agent.pth")
        print("âœ… Agent pÃ©riodique chargÃ© avec succÃ¨s")
    except FileNotFoundError:
        print("âŒ Fichier periodic_agent.pth non trouvÃ©")
        return
    except Exception as e:
        print(f"âŒ Erreur lors du chargement de l'agent pÃ©riodique: {e}")
        return
    
    # Test des agents
    test_single_agent(immediate_agent, env, "MISE Ã€ JOUR IMMÃ‰DIATE")
    
    # CrÃ©er un nouvel environnement pour le deuxiÃ¨me agent
    env2 = GridWorld(size=5)
    test_single_agent(periodic_agent, env2, "MISE Ã€ JOUR PÃ‰RIODIQUE")
    
    # Test de performance quantitative
    print(f"\n{'='*60}")
    print("TEST DE PERFORMANCE QUANTITATIVE")
    print(f"{'='*60}")
    
    imm_score, imm_success = test_performance(immediate_agent, "ImmÃ©diat")
    peri_score, peri_success = test_performance(periodic_agent, "PÃ©riodique")
    
    # Comparaison finale
    print(f"\n{'='*60}")
    print("COMPARAISON FINALE")
    print(f"{'='*60}")
    print(f"ğŸ”µ ImmÃ©diat  - Score: {imm_score:.2f}, SuccÃ¨s: {imm_success:.1f}%")
    print(f"ğŸ”´ PÃ©riodique - Score: {peri_score:.2f}, SuccÃ¨s: {peri_success:.1f}%")
    
    if imm_score > peri_score:
        print("ğŸ–ï¸  L'agent IMMÃ‰DIAT performe mieux!")
    elif peri_score > imm_score:
        print("ğŸ–ï¸  L'agent PÃ‰RIODIQUE performe mieux!")
    else:
        print("âš–ï¸  Les deux agents ont des performances similaires!")

if __name__ == "__main__":
    compare_agents()